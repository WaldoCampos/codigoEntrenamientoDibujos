{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa744100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.byol_parallel import BYOL_parallel\n",
    "from models.byol_pytorch import BYOL\n",
    "from data.custom_transforms import BatchTransform, ListToTensor, PadToSquare, SelectFromTuple\n",
    "from data.pairs_dataset import PairsDataset, pair_collate_fn\n",
    "\n",
    "from data.multi_pairs_dataset import MultiPairsDataset\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from torchvision import datasets\n",
    "import warnings\n",
    "\n",
    "\n",
    "# distributed training\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ece26c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c551673",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TransFormSquare:\n",
    "\n",
    "    def __init__(self, size):\n",
    "\n",
    "        self.size = size\n",
    "        self.x_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                PadToSquare(255),\n",
    "                T.Resize((self.size,self.size)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.y_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                PadToSquare(255),\n",
    "                T.Resize((self.size,self.size)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.x_transform(x) , self.y_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd19f4e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ecommerce = {\"images\" : '/home/vision/smb-datasets/ecommerce/images/train/',\n",
    "             \"sketches\" : '/home/vision/smb-datasets/ecommerce/ecommerce_pidinet/'}\n",
    "\n",
    "save_file = 'bimodal_byol_shoes_utils/checkpoints/Test/test_BYOl_parallel_training.pt'\n",
    "pretrained_model = 'bimodal_byol_shoes_utils/checkpoints/bimodal_byol_resnet50_pretrained_sketchy_v5.pt'\n",
    "\n",
    "\n",
    "ecommerce_dataset = PairsDataset(\n",
    "    ecommerce[\"images\"],\n",
    "    ecommerce[\"sketches\"],\n",
    "    transform=TransFormSquare(224)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "500073e6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def setup(rank, worls_size):\n",
    "\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12355\"\n",
    "\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=worls_size)\n",
    "\n",
    "def prepare(rank, world_soze, batch_size=32, pin_memory=False, num_workers=0):\n",
    "\n",
    "    dataset = ecommerce_dataset\n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank,\n",
    "                                 shuffle=False, drop_last=False)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=pin_memory,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        sampler=sampler)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5909a62",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hooking\n",
      "cpu\n",
      "dict_keys([device(type='cpu')])\n",
      "cpu\n",
      "dict_keys([device(type='cpu')])\n",
      "cpu\n",
      "dict_keys([device(type='cpu')])\n",
      "cpu\n",
      "dict_keys([device(type='cpu')])\n"
     ]
    }
   ],
   "source": [
    "encoder = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "empty_transform = T.Compose([])\n",
    "\n",
    "learner = BYOL(\n",
    "    encoder,\n",
    "    image_size=224,\n",
    "    hidden_layer=\"avgpool\",\n",
    "    augment_fn=empty_transform\n",
    "    #cosine_ema_steps=epochs*epoch_size\n",
    ")\n",
    "\n",
    "torch.save(learner.state_dict(), save_file.format(epochs))\n",
    "learner.load_state_dict(torch.load( save_file.format(epochs)))\n",
    "\n",
    "# optimizador\n",
    "opt = torch.optim.Adam(learner.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc6be330",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main(rank, world_size):\n",
    "    #setup the process groups\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    #prepare the dataloader\n",
    "    dataloader = prepare(rank, world_size)\n",
    "\n",
    "    #instaDP\n",
    "\n",
    "    # wrap the model with DDP\n",
    "    # device_ids tell DDP where is your model\n",
    "    # output_device tells DDP where to output, in our case, it is rank\n",
    "    # find_unused_parameters=True instructs DDP to find unused output of the forward() function of any module in the model\n",
    "\n",
    "    model = DDP(learner, device_ids=[rank], output_device=rank, find_unused_parameters=True)\n",
    "\n",
    "    optimizer = opt()\n",
    "\n",
    "    running_loss = np.array([], dtype=np.float32)\n",
    "    for epoch in range(epochs):\n",
    "        # if we are using DistributedSampler, we have to tell it whicj epoch this is\n",
    "        dataloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        for step, (x,y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            loss = learner(x,y)#.to('cuda', dtype=torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "            learner.module.update_moving_average()\n",
    "\n",
    "            running_loss = np.append(running_loss, [loss.mean().item()])\n",
    "            sys.stdout.write('\\rEpoch {}, batch {} - loss {:.4f}'.format(epoch+1, i+1, np.mean(running_loss)))\n",
    "\n",
    "            #i += 1\n",
    "            #if i%(epoch_size/2)==0:\n",
    "            #    torch.save(learner.state_dict(), save_file.format(epoch + 1))\n",
    "\n",
    "\n",
    "        torch.save(learner.state_dict(), save_file.format(epoch + 1))\n",
    "        running_loss = np.array([], dtype=np.float32)\n",
    "        sys.stdout.write('\\n')\n",
    "\n",
    "    cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5117dbe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'main' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'main' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "ProcessExitedException",
     "evalue": "process 1 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspawn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m     \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m     \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:240\u001b[0m, in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    236\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis method only supports start_method=spawn (got: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    237\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTo use a different start_method use:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    238\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m torch.multiprocessing.start_processes(...)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m start_method)\n\u001b[1;32m    239\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdaemon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspawn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:198\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/multiprocessing/spawn.py:149\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    141\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with signal \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    142\u001b[0m             (error_index, name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m             signal_name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    147\u001b[0m         )\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProcessExitedException(\n\u001b[1;32m    150\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with exit code \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    151\u001b[0m             (error_index, exitcode),\n\u001b[1;32m    152\u001b[0m             error_index\u001b[38;5;241m=\u001b[39merror_index,\n\u001b[1;32m    153\u001b[0m             error_pid\u001b[38;5;241m=\u001b[39mfailed_process\u001b[38;5;241m.\u001b[39mpid,\n\u001b[1;32m    154\u001b[0m             exit_code\u001b[38;5;241m=\u001b[39mexitcode\n\u001b[1;32m    155\u001b[0m         )\n\u001b[1;32m    157\u001b[0m original_trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_queues[error_index]\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    158\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 1 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "\n",
    "world_size = 2\n",
    "\n",
    "mp.spawn(main,\n",
    "     args=(world_size),\n",
    "     nprocs=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60827158",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hooking\n",
      "cpu\n",
      "dict_keys([device(type='cpu')])\n",
      "cpu\n",
      "dict_keys([device(type='cpu')])\n"
     ]
    }
   ],
   "source": [
    "encoder = models.resnet50(weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "empty_transform = T.Compose([])\n",
    "\n",
    "learner = BYOL(\n",
    "    encoder,\n",
    "    image_size=224,\n",
    "    hidden_layer=\"avgpool\",\n",
    "    augment_fn=empty_transform\n",
    "    #cosine_ema_steps=epochs*epoch_size\n",
    ")\n",
    "\n",
    "learner = DDP(learner)\n",
    "\n",
    "\n",
    "# optimizador\n",
    "opt = torch.optim.Adam(learner.parameters(), lr=3e-4)\n",
    "\n",
    "epochs = 3\n",
    "epoch_size = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06aa0da",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(learner.state_dict(), save_file.format(epochs))\n",
    "learner.load_state_dict(torch.load( save_file.format(epochs)))\n",
    "\n",
    "learner.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "509b43c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "cuda:0\n",
      "dict_keys([device(type='cuda', index=0)])\n",
      "cuda:0\n",
      "dict_keys([device(type='cuda', index=0)])\n",
      "cuda:0\n",
      "dict_keys([device(type='cuda', index=0)])\n",
      "cuda:0\n",
      "dict_keys([device(type='cuda', index=0)])\n",
      "cuda:1\n",
      "dict_keys([device(type='cuda', index=1)])\n",
      "cuda:1\n",
      "dict_keys([device(type='cuda', index=1)])\n",
      "cuda:1\n",
      "dict_keys([device(type='cuda', index=1)])\n",
      "cuda:1\n",
      "dict_keys([device(type='cuda', index=1)])\n",
      "Epoch 1, batch 1 - loss 3.92631\n",
      "cuda:0\n",
      "dict_keys([device(type='cuda', index=0), device(type='cuda', index=1)])\n",
      "cuda:1\n",
      "dict_keys([])\n",
      "cuda:0\n",
      "dict_keys([device(type='cuda', index=0)])\n",
      "cuda:0\n",
      "dict_keys([device(type='cuda', index=0)])\n",
      "cuda:0\n",
      "dict_keys([device(type='cuda', index=0)])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "Caught KeyError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/users/btorres/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/users/btorres/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/users/btorres/proyectos/redesNeuronales/models/byol_parallel.py\", line 223, in forward\n    online_proj_one = self.online_encoder(image_one)\n  File \"/users/btorres/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/users/btorres/proyectos/redesNeuronales/models/byol_parallel.py\", line 170, in forward\n    representation = self.get_representation(x)\n  File \"/users/btorres/proyectos/redesNeuronales/models/byol_parallel.py\", line 162, in get_representation\n    hidden = self.hidden[x.device]\nKeyError: device(type='cuda', index=1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (x,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(step)\n\u001b[0;32m---> 13\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mlearner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#.to('cuda', dtype=torch.float)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/users/btorres/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/users/btorres/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/users/btorres/proyectos/redesNeuronales/models/byol_parallel.py\", line 223, in forward\n    online_proj_one = self.online_encoder(image_one)\n  File \"/users/btorres/proyectos/redesNeuronales/venv/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/users/btorres/proyectos/redesNeuronales/models/byol_parallel.py\", line 170, in forward\n    representation = self.get_representation(x)\n  File \"/users/btorres/proyectos/redesNeuronales/models/byol_parallel.py\", line 162, in get_representation\n    hidden = self.hidden[x.device]\nKeyError: device(type='cuda', index=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "learner.train()\n",
    "filehandler = open('bimodal_byol_shoes_utils/training_bimodal_byol.txt', 'w')\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    running_loss = np.array([], dtype=np.float32)\n",
    "    for epoch in range(epochs):\n",
    "        i = 0\n",
    "\n",
    "        #for images in Loaders[int(epoch/epochsForLoader)]:\n",
    "        for step, (x,y) in enumerate(train_loader):\n",
    "            print(step)\n",
    "\n",
    "            loss = learner(x,y)#.to('cuda', dtype=torch.float)\n",
    "            opt.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            opt.step()\n",
    "            learner.module.update_moving_average()\n",
    "\n",
    "            running_loss = np.append(running_loss, [loss.mean().item()])\n",
    "            sys.stdout.write('\\rEpoch {}, batch {} - loss {:.4f}'.format(epoch+1, i+1, np.mean(running_loss)))\n",
    "            filehandler.write('Epoch {}, batch {} - loss {:.4f}\\n'.format(epoch+1, i+1, np.mean(running_loss)))\n",
    "            filehandler.flush()\n",
    "            i += 1\n",
    "            if i%(epoch_size/2)==0:\n",
    "                torch.save(learner.state_dict(), save_file.format(epoch + 1))\n",
    "\n",
    "\n",
    "        torch.save(learner.state_dict(), save_file.format(epoch + 1))\n",
    "        running_loss = np.array([], dtype=np.float32)\n",
    "        sys.stdout.write('\\n')\n",
    "        break\n",
    "filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245c69f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
